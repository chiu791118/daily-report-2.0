#!/usr/bin/env python3
"""
Daily Market Digest - Main Entry Point

Automated tool for generating daily market analysis reports.
Integrates news, YouTube content, and stock data with AI analysis.

Usage:
    python main.py pre-market    # Generate pre-market report (21:00 Taiwan)
    python main.py post-market   # Generate post-market report (05:00 Taiwan)
    python main.py saturday      # Generate Saturday industry report (09:00 Taiwan)
    python main.py sunday        # Generate Sunday outlook report (18:00 Taiwan)
    python main.py test          # Test all collectors and analyzers
"""

import argparse
import sys
from datetime import datetime
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

import pytz

from src.config.settings import (
    TIMEZONE,
    GEMINI_API_KEY,
    MIN_PRICE_CHANGE_PERCENT,
    ALWAYS_SHOW_PRIORITY,
    NOTION_API_KEY,
    NOTION_DATABASE_ID,
    US_EASTERN_TZ,
)
from src.collectors import NewsCollector, StockCollector
from src.analyzers import NewsAnalyzer, StockAnalyzer
from src.outputs import MarkdownReportGenerator, NotionPublisher


def check_api_keys():
    """Check if required API keys are set."""
    missing = []

    if not GEMINI_API_KEY:
        missing.append("GEMINI_API_KEY")
    if not NOTION_API_KEY or not NOTION_DATABASE_ID:
        missing.append("NOTION_API_KEY/NOTION_DATABASE_ID")

    if missing:
        print("âš ï¸  Missing required API keys:")
        for key in missing:
            print(f"   - {key}")
        print("\nPlease set these in your .env file.")
        return False

    return True


def extract_tickers_from_report(report_content: str, all_symbols: set) -> list[str]:
    """
    Extract stock tickers mentioned in the report content.
    Returns tickers sorted by frequency of mention.
    """
    import re
    from collections import Counter

    # Find all potential ticker mentions (uppercase 1-5 letter words)
    # Match patterns like: AAPL, $AAPL, **AAPL**, AAPL:, (AAPL)
    pattern = r'(?:^|[\s\$\*\(\|])([A-Z]{1,5})(?:[\s\*\)\|\:\,\.]|$)'
    matches = re.findall(pattern, report_content)

    # Count only tickers that are in our watchlist
    ticker_counts = Counter()
    for match in matches:
        if match in all_symbols:
            ticker_counts[match] += 1

    # Return top tickers sorted by frequency
    return [ticker for ticker, _ in ticker_counts.most_common(15)]


def filter_relevant_stocks(stocks: list, news_items: list, min_change: float = 3.0) -> dict:
    """
    Filter stocks to only show relevant ones:
    - Stocks mentioned in news
    - Stocks with significant price changes
    - Priority stocks (always shown)
    """
    # Get tickers mentioned in news
    news_tickers = set()
    for item in news_items:
        news_tickers.update(item.related_tickers)

    # Categorize stocks
    result = {
        "news_related": [],      # Mentioned in today's news
        "significant_movers": [], # Big price changes
        "priority": [],          # Priority watchlist
    }

    priority_symbols = {"AAPL", "AMD", "ARKK", "CHWY", "DXYZ", "MCHI", "MRNA", "PYPL", "TAL", "XYZ"}

    for stock in stocks:
        # Check if mentioned in news
        if stock.symbol in news_tickers:
            result["news_related"].append(stock)
        # Check if significant mover
        elif abs(stock.change_percent) >= min_change:
            result["significant_movers"].append(stock)
        # Check if priority
        elif stock.symbol in priority_symbols and ALWAYS_SHOW_PRIORITY:
            result["priority"].append(stock)

    return result
def generate_pre_market_report():
    """
    Generate pre-market report V3 (focused briefing format).
    """
    print("\n" + "="*60)
    print("ğŸ“ˆ Generating Pre-Market Report V3")
    print("="*60)

    tz_tw = pytz.timezone(TIMEZONE)
    tz_et = pytz.timezone(US_EASTERN_TZ)
    now_tw = datetime.now(tz_tw)
    now_et = now_tw.astimezone(tz_et)

    date_tw_str = now_tw.strftime("%Y-%m-%d")
    date_et = now_et.date()
    print(f"Time: {now_et.strftime('%Y-%m-%d %H:%M')} (ET) / {now_tw.strftime('%Y-%m-%d %H:%M')} ({TIMEZONE})\n")

    # Initialize components
    news_collector = NewsCollector()
    stock_collector = StockCollector()
    report_generator = MarkdownReportGenerator()

    from src.collectors.sec_edgar import SECEdgarCollector
    from src.collectors.fda import FDACollector
    from src.collectors.economic_calendar import EconomicCalendarCollector
    from src.collectors.earnings import EarningsCalendarCollector
    from src.collectors.universe import UniverseCollector
    from src.analyzers.pre_market_v3 import PreMarketV3Analyzer

    # Collect news
    print("ğŸ“° Collecting news...")
    news_items = news_collector.collect_all()
    print(f"   Found {len(news_items)} news items")

    # Market overview
    print("\nğŸ“Š Fetching market data...")
    market_overview = stock_collector.get_market_overview()

    # Watchlist
    print("ğŸ“‹ Fetching watchlist...")
    all_stocks = stock_collector.collect_watchlist()
    print(f"   Collected {len(all_stocks)} stocks")

    # Economic calendar
    print("\nğŸ—“ï¸  Fetching economic calendar...")
    econ_collector = EconomicCalendarCollector()
    econ_events = econ_collector.get_events_for_date(date_et)
    econ_rows = econ_collector.to_report_rows(econ_events)
    if econ_collector.last_warning:
        print(f"   âš ï¸ {econ_collector.last_warning}")
    else:
        print(f"   Found {len(econ_events)} economic events")

    # Earnings calendar
    print("\nğŸ’¼ Fetching earnings calendar...")
    earnings_collector = EarningsCalendarCollector()
    earnings_events = earnings_collector.get_events_for_date(date_et)
    earnings_rows = earnings_collector.to_report_rows(earnings_events)
    if earnings_collector.last_warning:
        print(f"   âš ï¸ {earnings_collector.last_warning}")
    else:
        print(f"   Found {len(earnings_events)} earnings events")

    # Universe for event-driven tickers
    print("\nğŸŒ Building universe...")
    universe_collector = UniverseCollector()
    universe_data = universe_collector.get_universe()
    if universe_collector.last_warning:
        print(f"   âš ï¸ {universe_collector.last_warning}")
    else:
        print(f"   Universe size: {len(universe_data.tickers)} tickers")

    # Collect SEC 8-K filings (past 48 hours)
    sec_summary = ""
    try:
        print("\nğŸ“‹ Collecting SEC 8-K filings...")
        sec_collector = SECEdgarCollector()
        sec_filings = sec_collector.collect_recent_filings(
            form_types=["8-K"],
            hours_lookback=48,
            max_per_type=20,
        )
        if sec_filings:
            sec_lines = ["### ğŸ“‹ è¿‘æœŸ SEC 8-K å…¬å‘Š\n"]
            for filing in sec_filings[:10]:
                items_str = ", ".join(filing.metadata.get("items", [])[:2]) if filing.metadata.get("items") else ""
                sec_lines.append(f"- **{filing.title}** {f'({items_str})' if items_str else ''}")
            sec_summary = "\n".join(sec_lines)
    except Exception as e:
        print(f"   âš ï¸ SEC collection error: {e}")

    # Collect FDA updates (past 48 hours)
    fda_summary = ""
    try:
        print("ğŸ¥ Collecting FDA updates...")
        fda_collector = FDACollector()
        fda_updates = fda_collector.collect_all(days_lookback=2, max_results=10)
        if fda_updates:
            fda_lines = ["### ğŸ¥ FDA æœ€æ–°å‹•æ…‹\n"]
            for update in fda_updates[:5]:
                if update.summary:
                    summary_text = update.summary[:150] + "..." if len(update.summary) > 150 else update.summary
                    fda_lines.append(f"- **[{update.category}]** {update.title}")
                    fda_lines.append(f"  - {summary_text}")
                else:
                    fda_lines.append(f"- **[{update.category}]** {update.title}")
            fda_summary = "\n".join(fda_lines)
    except Exception as e:
        print(f"   âš ï¸ FDA collection error: {e}")

    # Combine regulatory updates
    regulatory_updates = ""
    if sec_summary or fda_summary:
        regulatory_parts = []
        if sec_summary:
            regulatory_parts.append(sec_summary)
        if fda_summary:
            regulatory_parts.append(fda_summary)
        regulatory_updates = "\n\n".join(regulatory_parts)

    # Generate report sections with LLM
    print("\nğŸ¤– Generating V3 sections...")
    analyzer = PreMarketV3Analyzer()
    sections, meta = analyzer.generate_sections(
        market_overview=market_overview,
        economic_events=econ_events,
        earnings_events=earnings_events,
        news_items=news_items,
        watchlist_stocks=all_stocks,
        universe_data=universe_data,
    )

    # Generate final report
    print("\nğŸ“ Generating final report...")
    report = report_generator.generate_pre_market_report_v3(
        sections=sections,
        market_overview=market_overview,
        economic_rows=econ_rows,
        earnings_rows=earnings_rows,
        news_digest=meta.get("news_digest", []),
        regulatory_updates=regulatory_updates,
        economic_note=econ_collector.last_warning,
        earnings_note=earnings_collector.last_warning,
    )

    # Upload to Notion
    print("\nğŸ“¤ Uploading to Notion...")
    title_date = now_tw.strftime("%y%m%d")
    title = f"{title_date}_Pre-market"

    tags = (meta.get("watchlist_focus_symbols", []) + meta.get("event_driven_symbols", []))[:10]
    print(f"   Tags: {tags}")

    notion_publisher = NotionPublisher()
    page_url = notion_publisher.create_daily_page(
        title=title,
        content=report,
        report_type="pre-market",
        date_str=date_tw_str,
        tags=tags,
    )
    print(f"\nâœ… Pre-market report V3 uploaded to Notion: {page_url}")

    return page_url


def generate_post_market_report():
    """Generate post-market report (review of trading day, comparison with pre-market)."""
    print("\n" + "="*60)
    print("ğŸ“‰ Generating Post-Market Report")
    print("="*60)

    tz = pytz.timezone(TIMEZONE)
    now = datetime.now(tz)
    print(f"Time: {now.strftime('%Y-%m-%d %H:%M')} ({TIMEZONE})\n")

    # è¨ˆç®—ç¾è‚¡äº¤æ˜“æ—¥
    # Post-market å ±å‘Šæ°¸é å ±å‘Šã€Œå‰ä¸€å€‹äº¤æ˜“æ—¥ã€çš„çµæœ
    # å› ç‚ºå ±å‘Šåœ¨ç¾è‚¡æ”¶ç›¤å¾Œç”Ÿæˆï¼ˆå°åŒ— 08:00 = ç¾è‚¡æ”¶ç›¤å¾Œ 3 å°æ™‚ï¼‰
    from datetime import timedelta
    from pathlib import Path
    from src.config.settings import REPORTS_DIR

    def get_previous_trading_day(date: datetime) -> datetime:
        """Get the previous trading day, skipping weekends."""
        result = date - timedelta(days=1)
        # Skip Sunday (6) -> go to Friday
        if result.weekday() == 6:  # Sunday
            result = result - timedelta(days=2)
        # Skip Saturday (5) -> go to Friday
        elif result.weekday() == 5:  # Saturday
            result = result - timedelta(days=1)
        return result

    # æ°¸é ä½¿ç”¨å‰ä¸€å€‹äº¤æ˜“æ—¥
    trading_day = get_previous_trading_day(now)
    trading_date = trading_day.strftime("%Y-%m-%d")

    print(f"ğŸ“… ç¾è‚¡äº¤æ˜“æ—¥: {trading_date} (å ±å‘Šç”Ÿæˆæ–¼ {now.strftime('%Y-%m-%d %H:%M')})")

    # è®€å–ç›¤å‰å ±å‘Š (å„ªå…ˆå¾ Notionï¼Œå…¶æ¬¡å¾æœ¬åœ°æª”æ¡ˆ)
    pre_market_content = ""
    notion_publisher = None

    # 1. å˜—è©¦å¾ Notion è®€å–
    print("ğŸ“– Fetching pre-market report from Notion...")
    try:
        notion_publisher = NotionPublisher()
        pre_market_content = notion_publisher.get_pre_market_content(trading_date)
    except Exception as e:
        print(f"   âš ï¸ Notion read error: {e}")
        notion_publisher = None

    # 2. å¦‚æœ Notion æ²’æœ‰ï¼Œå˜—è©¦æœ¬åœ°æª”æ¡ˆ
    if not pre_market_content:
        pre_market_path = REPORTS_DIR / trading_date / "pre-market.md"
        if pre_market_path.exists():
            print(f"ğŸ“– Reading pre-market report from local: {pre_market_path}")
            with open(pre_market_path, "r", encoding="utf-8") as f:
                pre_market_content = f.read()
        else:
            print(f"âš ï¸ No pre-market report found for {trading_date} (Notion or local)")

    # Initialize components
    news_collector = NewsCollector()
    stock_collector = StockCollector()
    stock_analyzer = StockAnalyzer()
    report_generator = MarkdownReportGenerator()

    # Import SEC and FDA collectors
    from src.collectors.sec_edgar import SECEdgarCollector
    from src.collectors.fda import FDACollector

    # Get news for context
    print("\nğŸ“° Collecting news...")
    news_items = news_collector.collect_all()

    # Collect SEC 8-K filings (past 24 hours for post-market)
    sec_summary = ""
    try:
        print("ğŸ“‹ Collecting SEC 8-K filings...")
        sec_collector = SECEdgarCollector()
        sec_filings = sec_collector.collect_recent_filings(
            form_types=["8-K"],
            hours_lookback=24,
            max_per_type=15
        )
        if sec_filings:
            print(f"   Found {len(sec_filings)} recent 8-K filings")
            sec_lines = ["### ğŸ“‹ ä»Šæ—¥ SEC 8-K å…¬å‘Š\n"]
            for filing in sec_filings[:8]:
                items_str = ", ".join(filing.metadata.get("items", [])[:2]) if filing.metadata.get("items") else ""
                sec_lines.append(f"- **{filing.title}** {f'({items_str})' if items_str else ''}")
            sec_summary = "\n".join(sec_lines)
        else:
            print("   No recent 8-K filings found")
    except Exception as e:
        print(f"   âš ï¸ SEC collection error: {e}")

    # Collect FDA updates (past 24 hours)
    fda_summary = ""
    try:
        print("ğŸ¥ Collecting FDA updates...")
        fda_collector = FDACollector()
        fda_updates = fda_collector.collect_all(days_lookback=1, max_results=8)
        if fda_updates:
            print(f"   Found {len(fda_updates)} FDA updates")
            fda_lines = ["### ğŸ¥ FDA æœ€æ–°å‹•æ…‹\n"]
            for update in fda_updates[:5]:
                # Include summary for context
                if update.summary:
                    summary_text = update.summary[:150] + "..." if len(update.summary) > 150 else update.summary
                    fda_lines.append(f"- **[{update.category}]** {update.title}")
                    fda_lines.append(f"  - {summary_text}")
                else:
                    fda_lines.append(f"- **[{update.category}]** {update.title}")
            fda_summary = "\n".join(fda_lines)
        else:
            print("   No recent FDA updates")
    except Exception as e:
        print(f"   âš ï¸ FDA collection error: {e}")

    # Get market data
    print("ğŸ“Š Fetching market data...")
    market_overview = stock_collector.get_market_overview()

    # Generate post-market review (comparing with pre-market predictions)
    print("ğŸ” Generating post-market review...")
    market_review = stock_analyzer.analyze_post_market_review(
        market_overview,
        pre_market_content=pre_market_content,
        news_items=news_items,
    )

    # Get watchlist with fundamental focus
    print("ğŸ“‹ Fetching watchlist...")
    all_stocks = stock_collector.collect_watchlist()
    watchlist_summary = stock_analyzer.generate_watchlist_fundamental_summary(
        all_stocks,
        news_items=news_items,
    )

    # Generate tomorrow outlook
    print("ğŸ”® Generating tomorrow outlook...")
    tomorrow_outlook = stock_analyzer.generate_tomorrow_outlook(news_items)

    # Check for after-hours news (earnings, announcements)
    after_hours_news = ""
    earnings_keywords = ["earnings", "è²¡å ±", "æ¥­ç¸¾", "after hours", "ç›¤å¾Œ"]
    after_hours_items = [
        n for n in news_items
        if any(kw in n.title.lower() for kw in earnings_keywords)
    ]
    if after_hours_items:
        after_hours_news = "\n".join([
            f"- [{item.source}] {item.title}"
            for item in after_hours_items[:5]
        ])

    # Combine regulatory updates
    regulatory_updates = ""
    if sec_summary or fda_summary:
        regulatory_parts = []
        if sec_summary:
            regulatory_parts.append(sec_summary)
        if fda_summary:
            regulatory_parts.append(fda_summary)
        regulatory_updates = "\n\n".join(regulatory_parts)

    # Generate report
    print("\nğŸ“ Generating report...")
    report = report_generator.generate_post_market_report(
        trading_date=trading_date,
        market_review=market_review,
        watchlist_summary=watchlist_summary,
        after_hours_news=after_hours_news,
        tomorrow_outlook=tomorrow_outlook,
        regulatory_updates=regulatory_updates,
    )

    # Upload to Notion (reuse publisher if already initialized)
    print("\nğŸ“¤ Uploading to Notion...")
    if not notion_publisher:
        notion_publisher = NotionPublisher()
    # Convert trading_date (YYYY-MM-DD) to YYMMDD format for title
    title_date = datetime.strptime(trading_date, "%Y-%m-%d").strftime("%y%m%d")
    title = f"{title_date}_Post-market"

    # Extract stock tickers from report content for tags
    all_symbols = {s.symbol for s in all_stocks}
    stock_tags = extract_tickers_from_report(report, all_symbols)[:10]
    print(f"   Tags from report: {stock_tags}")

    page_url = notion_publisher.create_daily_page(
        title=title,
        content=report,
        report_type="post-market",
        date_str=trading_date,
        tags=stock_tags,
    )
    print(f"\nâœ… Post-market report uploaded to Notion: {page_url}")

    return page_url


def generate_saturday_report(quick_mode: bool = False):
    """
    Generate Saturday industry analysis report (9am Taiwan = 1:00 UTC Saturday).

    This report uses the 6-prompt pipeline for deep industry analysis:
    1. Data classification and high-signal identification
    2. Paradigm shift analysis
    3. Technology frontier analysis
    4. Company moves analysis
    5. Final report generation

    Args:
        quick_mode: If True, use single-prompt quick analysis instead of full pipeline
    """
    print("\n" + "="*60)
    print("ğŸ“Š Generating Saturday Industry Cognition Report")
    print("="*60)

    tz = pytz.timezone(TIMEZONE)
    now = datetime.now(tz)
    print(f"Time: {now.strftime('%Y-%m-%d %H:%M')} ({TIMEZONE})\n")

    # Import new components
    from src.collectors.intel_aggregator import IntelAggregator
    from src.analyzers.industry_analyzer import IndustryAnalyzer

    # Initialize components
    intel_aggregator = IntelAggregator()
    industry_analyzer = IndustryAnalyzer()
    stock_collector = StockCollector()
    report_generator = MarkdownReportGenerator()

    # Collect intelligence from all sources (7 days lookback for weekly report)
    print("\nğŸ“¥ Collecting intelligence from all sources...")
    intel_items = intel_aggregator.collect_all(
        days_lookback=7,
        include_news=True,
        include_sec=True,
        include_arxiv=True,
        include_trials=True,
        include_fda=True,
    )

    # Get summary stats
    stats = intel_aggregator.get_summary_stats(intel_items)
    print(f"\nğŸ“Š Intelligence Summary:")
    print(f"   Total items: {stats['total']}")
    print(f"   By type: {stats['by_source_type']}")
    print(f"   Top entities: {list(stats['top_entities'].keys())[:5]}")

    # Get market overview for context
    print("\nğŸ“ˆ Fetching market data...")
    market_overview = stock_collector.get_market_overview()

    # Generate market summary
    market_summary_lines = []
    if market_overview.sp500:
        weekly = f" (æœ¬é€± {market_overview.sp500.change_1w:+.2f}%)" if market_overview.sp500.change_1w else ""
        market_summary_lines.append(f"- S&P 500: {market_overview.sp500.current_price:,.2f}{weekly}")
    if market_overview.nasdaq:
        weekly = f" (æœ¬é€± {market_overview.nasdaq.change_1w:+.2f}%)" if market_overview.nasdaq.change_1w else ""
        market_summary_lines.append(f"- NASDAQ: {market_overview.nasdaq.current_price:,.2f}{weekly}")
    if market_overview.dow:
        weekly = f" (æœ¬é€± {market_overview.dow.change_1w:+.2f}%)" if market_overview.dow.change_1w else ""
        market_summary_lines.append(f"- Dow Jones: {market_overview.dow.current_price:,.2f}{weekly}")
    if market_overview.vix:
        market_summary_lines.append(f"- VIX: {market_overview.vix:.2f}")
    week_market_summary = "\n".join(market_summary_lines)

    # Run industry analysis
    if quick_mode:
        print("\nğŸ¤– Running quick analysis (single prompt)...")
        industry_analysis = industry_analyzer.quick_analysis(intel_items[:100])
    else:
        print("\nğŸ¤– Running full 6-step analysis pipeline...")
        analysis_result = industry_analyzer.analyze(intel_items[:150], run_full_pipeline=True)
        industry_analysis = analysis_result.final_report

    # Get watchlist for additional context
    print("\nğŸ“‹ Fetching watchlist...")
    all_stocks = stock_collector.collect_watchlist()
    stock_analyzer = StockAnalyzer()
    watchlist_summary = stock_analyzer.generate_watchlist_summary(all_stocks)

    # Generate final report
    print("\nğŸ“ Generating final report...")
    report = report_generator.generate_saturday_report(
        week_market_summary=week_market_summary,
        industry_analysis=industry_analysis,
        watchlist_summary=watchlist_summary,
    )

    # Upload to Notion
    print("\nğŸ“¤ Uploading to Notion...")
    notion_publisher = NotionPublisher()
    date_str = now.strftime("%Y-%m-%d")
    title_date = now.strftime("%y%m%d")
    title = f"{title_date}_Saturday"

    # Extract tags from top entities and tickers
    top_tickers = list(stats['top_tickers'].keys())[:5]
    top_entities = [e for e in list(stats['top_entities'].keys())[:5] if len(e) <= 20]
    stock_tags = top_tickers + top_entities
    print(f"   Tags: {stock_tags[:10]}")

    page_url = notion_publisher.create_daily_page(
        title=title,
        content=report,
        report_type="saturday",
        date_str=date_str,
        tags=stock_tags[:10],
    )
    print(f"\nâœ… Saturday report uploaded to Notion: {page_url}")

    return page_url


def generate_sunday_report():
    """Generate Sunday weekly outlook report (6pm Taiwan = 10:00 UTC Sunday)."""
    print("\n" + "="*60)
    print("ğŸ”® Generating Sunday Weekly Outlook Report")
    print("="*60)

    tz = pytz.timezone(TIMEZONE)
    now = datetime.now(tz)
    print(f"Time: {now.strftime('%Y-%m-%d %H:%M')} ({TIMEZONE})\n")

    # Import IntelAggregator for comprehensive data collection
    from src.collectors.intel_aggregator import IntelAggregator

    # Initialize components
    intel_aggregator = IntelAggregator()
    stock_collector = StockCollector()
    stock_analyzer = StockAnalyzer()
    report_generator = MarkdownReportGenerator()

    # Collect intelligence from all sources (7 days lookback for weekly report)
    print("ğŸ“¥ Collecting intelligence from all sources...")
    intel_items = intel_aggregator.collect_all(
        days_lookback=7,
        include_news=True,
        include_sec=True,
        include_arxiv=True,
        include_trials=True,
        include_fda=True,
    )

    # Get summary stats
    stats = intel_aggregator.get_summary_stats(intel_items)
    print(f"   Total items: {stats['total']}")
    print(f"   By type: {stats['by_source_type']}")

    # Extract news items for compatibility with existing analyzers
    news_items = [item for item in intel_items if item.source_type.value == "news"]
    print(f"   News items: {len(news_items)}")

    # Get market overview
    print("ğŸ“Š Fetching market data...")
    market_overview = stock_collector.get_market_overview()

    # Generate weekly recap summary
    recap_lines = ["**æœ¬é€±æŒ‡æ•¸è¡¨ç¾ï¼š**"]
    if market_overview.sp500:
        weekly = f" (æœ¬é€± {market_overview.sp500.change_1w:+.2f}%)" if market_overview.sp500.change_1w else ""
        recap_lines.append(f"- S&P 500: {market_overview.sp500.current_price:,.2f}{weekly}")
    if market_overview.nasdaq:
        weekly = f" (æœ¬é€± {market_overview.nasdaq.change_1w:+.2f}%)" if market_overview.nasdaq.change_1w else ""
        recap_lines.append(f"- NASDAQ: {market_overview.nasdaq.current_price:,.2f}{weekly}")
    if market_overview.dow:
        weekly = f" (æœ¬é€± {market_overview.dow.change_1w:+.2f}%)" if market_overview.dow.change_1w else ""
        recap_lines.append(f"- Dow Jones: {market_overview.dow.current_price:,.2f}{weekly}")
    if market_overview.vix:
        recap_lines.append(f"- VIX: {market_overview.vix:.2f}")

    # Add weekly highlights from intel sources
    sec_items = [i for i in intel_items if i.source_type.value == "sec_filing"]
    fda_items = [i for i in intel_items if i.source_type.value == "regulatory"]
    arxiv_items = [i for i in intel_items if i.source_type.value == "research_paper"]

    if sec_items or fda_items or arxiv_items:
        recap_lines.append("\n**æœ¬é€±é‡è¦å…¬å‘Š/ç ”ç©¶ï¼š**")
        if sec_items:
            recap_lines.append(f"- SEC å…¬å‘Š: {len(sec_items)} ä»¶")
        if fda_items:
            recap_lines.append(f"- FDA å‹•æ…‹: {len(fda_items)} ä»¶")
        if arxiv_items:
            recap_lines.append(f"- AI/ML è«–æ–‡: {len(arxiv_items)} ç¯‡")

    weekly_recap = "\n".join(recap_lines)

    # Get watchlist
    print("ğŸ“‹ Fetching watchlist...")
    all_stocks = stock_collector.collect_watchlist()
    print(f"   Collected {len(all_stocks)} stocks")

    # Format intel highlights for outlook analysis
    intel_highlights = []
    for item in sec_items[:5]:
        intel_highlights.append(f"[SEC] {item.title}")
    for item in fda_items[:5]:
        intel_highlights.append(f"[FDA] {item.title}")
    for item in arxiv_items[:3]:
        intel_highlights.append(f"[Research] {item.title}")
    intel_context = "\n".join(intel_highlights) if intel_highlights else ""

    # Generate weekly outlook analysis
    print("ğŸ”® Generating weekly outlook...")
    weekly_outlook = stock_analyzer.analyze_weekly_outlook(
        all_stocks,
        market_overview,
        news_items=news_items,
        intel_context=intel_context,
    )

    # Generate watchlist summary with fundamental focus
    watchlist_summary = stock_analyzer.generate_watchlist_fundamental_summary(
        all_stocks,
        news_items=news_items,
    )

    # Generate report
    print("\nğŸ“ Generating report...")
    report = report_generator.generate_sunday_report(
        weekly_recap=weekly_recap,
        weekly_outlook=weekly_outlook,
        watchlist_summary=watchlist_summary,
    )

    # Upload to Notion
    print("\nğŸ“¤ Uploading to Notion...")
    notion_publisher = NotionPublisher()
    date_str = now.strftime("%Y-%m-%d")
    title_date = now.strftime("%y%m%d")
    title = f"{title_date}_Sunday"

    # Extract stock tickers from report content for tags
    all_symbols = {s.symbol for s in all_stocks}
    stock_tags = extract_tickers_from_report(report, all_symbols)[:10]
    print(f"   Tags from report: {stock_tags}")

    page_url = notion_publisher.create_daily_page(
        title=title,
        content=report,
        report_type="sunday",
        date_str=date_str,
        tags=stock_tags,
    )
    print(f"\nâœ… Sunday report uploaded to Notion: {page_url}")

    return page_url


def test_components():
    """Test all components without generating full reports."""
    print("\n" + "="*60)
    print("ğŸ§ª Testing Components")
    print("="*60)

    # Test News Collector
    print("\n1ï¸âƒ£ Testing News Collector...")
    try:
        collector = NewsCollector()
        news = collector.collect_all()
        print(f"   âœ… Collected {len(news)} news items")

        # Show source breakdown
        by_source = {}
        for item in news:
            by_source[item.source] = by_source.get(item.source, 0) + 1
        print("   Sources:")
        for source, count in sorted(by_source.items(), key=lambda x: -x[1]):
            print(f"      {source}: {count}")

        # Show ticker mentions
        ticker_news = [n for n in news if n.related_tickers]
        print(f"   News with ticker mentions: {len(ticker_news)}")

    except Exception as e:
        print(f"   âŒ Error: {e}")

    # Test Stock Collector
    print("\n2ï¸âƒ£ Testing Stock Collector...")
    try:
        collector = StockCollector()
        overview = collector.get_market_overview()
        print(f"   âœ… Market overview fetched")
        if overview.sp500:
            print(f"   S&P 500: {overview.sp500.current_price:,.2f} ({overview.sp500.change_percent:+.2f}%)")

        stocks = collector.collect_watchlist()
        print(f"   âœ… Collected {len(stocks)} stocks from watchlist")

        # Show big movers
        movers = [s for s in stocks if abs(s.change_percent) >= 3]
        if movers:
            print(f"   Big movers (>=3%):")
            for s in sorted(movers, key=lambda x: abs(x.change_percent), reverse=True)[:5]:
                print(f"      {s.symbol}: {s.change_percent:+.2f}%")

    except Exception as e:
        print(f"   âŒ Error: {e}")

    # Test AI Analyzers
    print("\n3ï¸âƒ£ Testing AI Analyzers...")
    if GEMINI_API_KEY:
        try:
            analyzer = NewsAnalyzer()
            print("   âœ… NewsAnalyzer initialized")

            analyzer = StockAnalyzer()
            print("   âœ… StockAnalyzer initialized")

            from src.analyzers.pre_market_analyzer import PreMarketAnalyzer
            analyzer = PreMarketAnalyzer()
            print("   âœ… PreMarketAnalyzer initialized")
        except Exception as e:
            print(f"   âŒ Error: {e}")
    else:
        print("   âš ï¸ Skipped (GEMINI_API_KEY not set)")

    print("\n" + "="*60)
    print("âœ… Component testing complete")
    print("="*60)


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Daily Market Digest - Automated market analysis tool",
    )

    parser.add_argument(
        "command",
        choices=["pre-market", "post-market", "saturday", "sunday", "test"],
        help="Report type to generate",
    )

    args = parser.parse_args()

    # Check API keys for non-test commands
    if args.command != "test" and not check_api_keys():
        sys.exit(1)

    try:
        if args.command == "pre-market":
            generate_pre_market_report()

        elif args.command == "post-market":
            generate_post_market_report()

        elif args.command == "saturday":
            generate_saturday_report()

        elif args.command == "sunday":
            generate_sunday_report()

        elif args.command == "test":
            test_components()

    except KeyboardInterrupt:
        print("\n\nâš ï¸ Operation cancelled by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
