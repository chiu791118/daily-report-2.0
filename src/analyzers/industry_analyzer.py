"""
Industry Analyzer Module
Implements the 6-prompt pipeline for weekly industry cognition report.

Pipeline:
1. Role & Principles Setup
2. Data Preprocessing & Classification
3. Paradigm Shift Analysis
4. Technology Progress Analysis
5. Company Moves Analysis
6. Final Report Generation
"""
from google import genai
from google.genai import types
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional
import json

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.config.settings import (
    GEMINI_API_KEY,
    GEMINI_MODEL,
)
from src.collectors.base import IntelItem


@dataclass
class AnalysisResult:
    """Container for multi-step analysis results."""
    # Step 2: Data classification
    classified_data: dict = field(default_factory=dict)
    high_signal_events: list = field(default_factory=list)

    # Step 3: Paradigm shifts
    paradigm_shifts: list = field(default_factory=list)

    # Step 4: Technology analysis
    tech_analysis: str = ""

    # Step 5: Company analysis
    company_analysis: str = ""

    # Step 6: Final report
    final_report: str = ""

    # Metadata
    processing_time: float = 0.0
    token_usage: dict = field(default_factory=dict)


class IndustryAnalyzer:
    """
    Analyzes industry intelligence using a multi-step prompt pipeline.

    Designed for the Saturday Weekly Industry Cognition Report.
    """

    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY not set in environment")

        self.client = genai.Client(api_key=GEMINI_API_KEY)
        self.model = GEMINI_MODEL

    def analyze(
        self,
        intel_items: list[IntelItem],
        run_full_pipeline: bool = True,
    ) -> AnalysisResult:
        """
        Run the full analysis pipeline.

        Args:
            intel_items: List of intelligence items
            run_full_pipeline: If False, only runs classification step

        Returns:
            AnalysisResult with all analysis outputs
        """
        import time
        start_time = time.time()

        result = AnalysisResult()

        # Format raw data
        raw_data = self._format_raw_data(intel_items)

        # Step 2: Classify and identify high-signal events
        print("ğŸ” Step 2: Classifying data and identifying high-signal events...")
        classification = self._step2_classify_data(raw_data)
        result.classified_data = classification.get("classified", {})
        result.high_signal_events = classification.get("high_signal_events", [])

        if not run_full_pipeline:
            return result

        # Step 3: Analyze paradigm shifts
        print("ğŸ”„ Step 3: Analyzing paradigm shifts...")
        result.paradigm_shifts = self._step3_paradigm_shifts(
            result.high_signal_events
        )

        # Step 4: Analyze technology progress
        print("ğŸ’» Step 4: Analyzing technology frontier...")
        result.tech_analysis = self._step4_technology_analysis(
            raw_data, result.high_signal_events
        )

        # Step 5: Analyze company moves
        print("ğŸ¢ Step 5: Analyzing company moves...")
        result.company_analysis = self._step5_company_analysis(
            raw_data, result.high_signal_events
        )

        # Step 6: Generate final report
        print("ğŸ“ Step 6: Generating final report...")
        result.final_report = self._step6_final_report(
            result.high_signal_events,
            result.paradigm_shifts,
            result.tech_analysis,
            result.company_analysis,
        )

        result.processing_time = time.time() - start_time
        print(f"âœ… Analysis complete in {result.processing_time:.1f}s")

        return result

    def _format_raw_data(self, intel_items: list[IntelItem]) -> str:
        """Format raw intelligence data for prompts."""
        lines = []

        # Group by source type
        by_type = {}
        for item in intel_items:
            st = item.source_type.value
            if st not in by_type:
                by_type[st] = []
            by_type[st].append(item)

        type_labels = {
            "news": "æ–°èå ±å°",
            "sec_filing": "SEC è²¡å ±/å…¬å‘Š",
            "research_paper": "ç ”ç©¶è«–æ–‡",
            "clinical_trial": "è‡¨åºŠè©¦é©—",
            "regulatory": "ç›£ç®¡å…¬å‘Š",
        }

        for source_type, items in by_type.items():
            label = type_labels.get(source_type, source_type)
            lines.append(f"\n### {label}\n")

            for item in items[:50]:  # Limit per type
                date_str = item.published.strftime("%m/%d")
                entities = ", ".join(item.related_entities[:3]) if item.related_entities else ""
                tickers = ", ".join([f"${t}" for t in item.related_tickers[:3]]) if item.related_tickers else ""
                tags = f" [{entities}]" if entities else (f" [{tickers}]" if tickers else "")

                lines.append(f"- [{date_str}] [{item.source}] {item.title}{tags}")
                if item.summary:
                    summary = item.summary[:200] + "..." if len(item.summary) > 200 else item.summary
                    lines.append(f"  {summary}")

        return "\n".join(lines)

    def _step2_classify_data(self, raw_data: str) -> dict:
        """
        Step 2: Classify data and identify high-signal events.

        Categories:
        a) ç›´æ¥äº‹å¯¦ (observable facts)
        b) è¡Œç‚ºè¨Šè™Ÿ (actions / decisions)
        c) ç´„æŸæˆ–æ¿€å‹µç·šç´¢ (constraints / incentives)
        d) å™ªéŸ³æˆ–é‡è¤‡è³‡è¨Š
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸–ç•Œç´šå…¨ç”¢æ¥­ã€å•†æ¥­èˆ‡ç§‘æŠ€ç ”ç©¶åˆå¤¥äººã€‚

**ã€æœ¬æ­¥é©Ÿé™åˆ¶ã€‘**
- ä¸å…è¨±é€²è¡Œä»»ä½•ç¬¬ä¸€æ€§åŸå‰‡ã€å®è§€è§£é‡‹æˆ–é«˜éšæ¨è«–
- ä¸å…è¨±ä½¿ç”¨ã€Œæœ¬è³ªä¸Šã€ã€Œå¾æ ¹æœ¬ä¸Šã€ç­‰æŠ½è±¡èªè¨€
- ä»»å‹™åƒ…é™æ–¼è¨Šè™Ÿåˆ†é¡èˆ‡é‡è¦æ€§ç¯©é¸

---

ä»¥ä¸‹æ˜¯æœ¬é€±æ”¶é›†çš„åŸå§‹è³‡æ–™ï¼ˆæ–°èã€ç ”ç©¶ã€è²¡å ±ã€è‡¨åºŠè©¦é©—ã€ç›£ç®¡å…¬å‘Šï¼‰ï¼š

{raw_data}

---

è«‹å…ˆä¸è¦å¯«å ±å‘Šã€‚è«‹ä½ å…ˆåšä¸‰ä»¶äº‹ï¼š

## 1. å°‡è³‡æ–™åˆ†é¡ç‚ºï¼š

a) **ç›´æ¥äº‹å¯¦ï¼ˆobservable factsï¼‰**
   - å¯é©—è­‰çš„æ•¸æ“šã€å…¬å‘Šã€çµæœ

b) **è¡Œç‚ºè¨Šè™Ÿï¼ˆactions / decisionsï¼‰**
   - å…¬å¸çš„å…·é«”è¡Œå‹•ã€ç­–ç•¥æ±ºç­–ã€äººäº‹è®Šå‹•

c) **ç´„æŸæˆ–æ¿€å‹µçš„ç·šç´¢ï¼ˆconstraints / incentivesï¼‰**
   - é€éœ²é™åˆ¶ã€å£“åŠ›ã€æˆ–å‹•æ©Ÿçš„è³‡è¨Š

d) **å™ªéŸ³æˆ–é‡è¤‡è³‡è¨Š**
   - åƒ¹å€¼ä¸é«˜æˆ–é‡è¤‡çš„å…§å®¹

## 2. æŒ‡å‡ºå“ªäº›è³‡è¨Šï¼š

- **æœƒæ”¹è®Šè¡Œæ¥­ã€ŒèªçŸ¥åœ°åœ–ã€** - é¡›è¦†æ—¢æœ‰å‡è¨­æˆ–é–‹å•Ÿæ–°å¯èƒ½
- **åªæ˜¯ç¢ºèªæ—¢æœ‰è¶¨å‹¢** - ç¬¦åˆé æœŸï¼Œå¼·åŒ–ç¾æœ‰åˆ¤æ–·
- **ç›®å‰ç„¡æ³•åˆ¤æ–·åƒ¹å€¼** - éœ€è¦æ›´å¤šè³‡è¨Šæ‰èƒ½è©•ä¼°

## 3. æ˜ç¢ºåˆ—å‡ºï¼š

**æœ¬é€±æœ€é‡è¦çš„ 5-8 å€‹ã€Œé«˜ä¿¡è™Ÿäº‹ä»¶ã€**

å°æ¯å€‹äº‹ä»¶èªªæ˜ï¼š
- äº‹ä»¶æ‘˜è¦ï¼ˆä¸€å¥è©±ï¼‰
- ç‚ºä½•é¸å®ƒè€Œéå…¶ä»–è³‡è¨Š
- å®ƒå±¬æ–¼ä¸Šè¿°å“ªå€‹åˆ†é¡
- å®ƒæœƒæ”¹è®ŠèªçŸ¥åœ°åœ–é‚„æ˜¯ç¢ºèªè¶¨å‹¢

è«‹ä»¥çµæ§‹åŒ–æ ¼å¼ï¼ˆJSON-likeï¼‰å›ç­”ï¼Œæ–¹ä¾¿å¾ŒçºŒè™•ç†ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.2,
                    max_output_tokens=4000,
                ),
            )
            return {"raw_response": response.text, "high_signal_events": [], "classified": {}}
        except Exception as e:
            return {"error": str(e), "high_signal_events": [], "classified": {}}

    def _step3_paradigm_shifts(self, high_signal_events: list) -> list:
        """
        Step 3: Analyze paradigm shifts from high-signal events.
        """
        # Use the raw response from step 2 which contains high signal events
        events_text = high_signal_events if isinstance(high_signal_events, str) else str(high_signal_events)

        prompt = f"""åŸºæ–¼ä»¥ä¸‹é«˜ä¿¡è™Ÿäº‹ä»¶çš„åˆ†æï¼š

{events_text}

---

**ã€ç¯„å¼ç§»è½‰åˆ¤æ–·çš„å¿…è¦æ¢ä»¶ã€‘**

åœ¨åˆ¤æ–·ä»»ä½•ã€Œç¯„å¼ç§»è½‰ã€æ™‚ï¼Œä½ å¿…é ˆå…ˆå›ç­”ä»¥ä¸‹ç¬¬ä¸€æ€§åŸå‰‡å•é¡Œï¼Œå¦å‰‡ä¸å¾—å®£ç¨±ç‚ºç¯„å¼ç§»è½‰ï¼š

1. è©²è¡Œæ¥­ä¸­ï¼Œå“ªä¸€å€‹ã€Œä¸å¯å£“ç¸®çš„åŸºæœ¬ç´„æŸã€æ­£åœ¨æ”¹è®Šï¼Ÿ
   ï¼ˆä¾‹å¦‚ï¼šç‰©ç†é™åˆ¶ã€ç¶“æ¿Ÿä¸‹é™ã€æ™‚é–“ã€é¢¨éšªã€åˆè¦ã€èªçŸ¥æˆæœ¬ï¼‰

2. è©²ç´„æŸéå»ç‚ºä½•ä¸å¯çªç ´ï¼Ÿç¾åœ¨æ˜¯ä»€éº¼æ”¹è®Šè®“å®ƒé¬†å‹•ï¼Ÿ

3. è‹¥å¿½ç•¥ç•¶å‰ç”¢å“ã€å…¬å¸èˆ‡æ•˜äº‹ï¼Œå¾ç¬¬ä¸€æ€§åŸå‰‡é‡æ–°æ¨å°ï¼Œè¡Œæ¥­çµæ§‹æ˜¯å¦å¿…ç„¶æ”¹å¯«ï¼Ÿ

è«‹æ˜ç¢ºæ¨™è¨»ï¼šã€First-principles lensã€‘ä¸¦ç”¨ä¸è¶…é 3 å¥è©±å®Œæˆã€‚

---

è«‹å›ç­”ï¼š

## 1. æ˜¯å¦å­˜åœ¨ä»¥ä¸‹é¡å‹çš„è®ŠåŒ–ï¼ˆå¦‚æœ‰ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºï¼‰ï¼š

- **æˆæœ¬æ›²ç·šæ”¹è®Š** - æŸé …èƒ½åŠ›çš„æˆæœ¬çµæ§‹ç™¼ç”Ÿè³ªè®Š
- **æ€§èƒ½/æ•ˆç‡æ›²ç·šèºé·** - æŠ€è¡“èƒ½åŠ›å‡ºç¾éšèºå¼æå‡
- **ä¾›çµ¦æˆ–é…é¡ç´„æŸæ”¹è®Š** - è³‡æºã€ç”¢èƒ½ã€å‡†å…¥çš„é™åˆ¶è®ŠåŒ–
- **åˆè¦/æ³•å¾‹é‚Šç•Œç§»å‹•** - ç›£ç®¡æ¡†æ¶çš„å¯¦è³ªæ”¹è®Š
- **çµ„ç¹”æˆ–å¹³å°æ²»ç†æ–¹å¼è½‰è®Š** - æ¬ŠåŠ›çµæ§‹æˆ–æ±ºç­–æ¨¡å¼æ”¹è®Š

## 2. å°‡é€™äº›è®ŠåŒ–è¡¨è¿°ç‚ºã€Œå¾ A â†’ Bã€çš„ç¯„å¼ç§»è½‰å¥å‹

ä¾‹å¦‚ï¼š
- å¾ã€Œå·¥å…·å‹ AIã€â†’ã€Œè‡ªæ²»å·¥ä½œä»£ç†ã€
- å¾ã€Œæ¸›é‡è—¥ç‰©ã€â†’ã€Œä»£è¬ç–¾ç—…å¹³å°ã€
- å¾ã€Œæ™¶ç‰‡ä¾›æ‡‰å•†ã€â†’ã€ŒAI åŸºç¤è¨­æ–½å£Ÿæ–·è€…ã€

## 3. å°æ¯ä¸€å€‹æ½›åœ¨ç¯„å¼ç§»è½‰ï¼Œèªªæ˜ï¼š

| é …ç›® | èªªæ˜ |
|------|------|
| **é©…å‹•æ©Ÿåˆ¶** | æ˜¯ä»€éº¼ï¼ˆä¸æ˜¯äº‹ä»¶ï¼‰åœ¨æ¨å‹•é€™å€‹è®ŠåŒ–ï¼Ÿ |
| **é‡æ–°å®šåƒ¹** | å“ªäº›è§’è‰²/å…¬å¸/èƒ½åŠ›æœƒè¢«é‡æ–°å®šåƒ¹ï¼Ÿèª°å—ç›Šï¼Ÿèª°å—æï¼Ÿ |
| **æ™‚é–“å°ºåº¦** | çŸ­æœŸï¼ˆ<6æœˆï¼‰/ ä¸­æœŸï¼ˆ6-18æœˆï¼‰/ é•·æœŸï¼ˆ>18æœˆï¼‰ |
| **ä¿¡å¿ƒç¨‹åº¦** | é«˜ï¼ˆæœ‰æ˜ç¢ºè­‰æ“šï¼‰/ ä¸­ï¼ˆåˆç†æ¨è«–ï¼‰/ ä½ï¼ˆæ—©æœŸå‡èªªï¼‰ |

è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä»¥é¡§å•èªè¨€æ’°å¯«ã€‚æ˜ç¢ºå€åˆ†ã€äº‹å¯¦ã€‘ã€æ¨è«–ã€‘ã€å‡èªªã€‘ã€‚"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                    max_output_tokens=3000,
                ),
            )
            return [{"raw_response": response.text}]
        except Exception as e:
            return [{"error": str(e)}]

    def _step4_technology_analysis(self, raw_data: str, high_signal_events) -> str:
        """
        Step 4: Analyze technology progress with workflow focus.
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸–ç•Œç´šç§‘æŠ€ç ”ç©¶åˆå¤¥äººã€‚

**ã€æœ¬æ­¥é©Ÿçš„ç¬¬ä¸€æ€§åŸå‰‡è¦æ±‚ã€‘**

åœ¨åˆ†æä»»ä½•æŠ€è¡“å½±éŸ¿æ™‚ï¼Œä½ å¿…é ˆå…ˆåšã€Œç¬¬ä¸€æ€§åŸå‰‡ä¸‹çš„å·¥ä½œæ‹†è§£ã€ï¼š

- è©²å·¥ä½œçš„ä¸å¯å†åˆ†å–®ä½ï¼ˆirreducible unitï¼‰æ˜¯ä»€éº¼ï¼Ÿ
- äººé¡éå»ç‚ºä½•å¿…é ˆè¦ªè‡ªå®Œæˆé€™ä¸€å–®ä½ï¼Ÿ
- æŠ€è¡“ç¾åœ¨æ˜¯æ›¿ä»£ã€åŠ é€Ÿï¼Œé‚„æ˜¯é‡æ§‹é€™ä¸€å–®ä½ï¼Ÿ

**ç¦æ­¢ï¼š**
- å¾åŠŸèƒ½æ¸…å–®æˆ–å·¥å…·ç‰¹æ€§å‡ºç™¼
- ä½¿ç”¨ã€Œæ•ˆç‡æå‡ã€ã€Œæ›´è°æ˜ã€ç­‰æ¨¡ç³Šè©å½™

---

åŸºæ–¼ä»¥ä¸‹è³‡æ–™ï¼Œåˆ†ææœ¬é€±çš„æŠ€è¡“é€²å±•ï¼š

{raw_data[:8000]}

---

å°æ–¼æ‰€æœ‰æŠ€è¡“ç›¸é—œé€²å±•ï¼ˆAIã€æ™¶ç‰‡ã€ç”ŸæŠ€å¹³å°ã€è»Ÿé«”å·¥å…·ï¼‰ï¼š

**è«‹ä¸è¦æè¿°æŠ€è¡“æœ¬èº«ï¼Œè€Œæ˜¯ç”¨ä»¥ä¸‹çµæ§‹è¼¸å‡ºï¼š**

## æŠ€è¡“é€²å±•åˆ†æ

å°æ¯é …é‡è¦æŠ€è¡“é€²å±•ï¼š

### [æŠ€è¡“/ç”¢å“åç¨±]

**1. Capability Deltaï¼ˆèƒ½åŠ›å·®åˆ†ï¼‰**
- æ–°å¢äº†ä»€éº¼ã€Œä»¥å‰åšä¸åˆ°ã€æˆ–ã€Œæˆæœ¬ä¸å¯æ¥å—ã€çš„èƒ½åŠ›ï¼Ÿ
- é‡åŒ–å·®è·ï¼ˆå¦‚æœæœ‰æ•¸æ“šï¼‰

**2. Workflow Rewriteï¼ˆå·¥ä½œæµå¦‚ä½•è¢«æ”¹å¯«ï¼‰**
- å“ªäº›å…·é«”å·¥ä½œç’°ç¯€è¢«æ›¿ä»£ / é‡æ§‹ / åŠ é€Ÿï¼Ÿ
- Before vs After æ˜¯ä»€éº¼ï¼Ÿ
- èª°çš„å·¥ä½œå—å½±éŸ¿æœ€å¤§ï¼Ÿ

**3. Elite Usage Patternï¼ˆé ‚å°–äººæ‰æ€éº¼ç”¨ï¼‰**
- ä»»å‹™å¦‚ä½•è¢«æ‹†è§£ï¼Ÿ
- Agent / å·¥å…·å¦‚ä½•è¢«ç·¨æ’ï¼Ÿ
- å“ªäº›å·¥ä½œä»å¿…é ˆç”±äººæ‰¿æ“”ï¼Ÿç‚ºä»€éº¼ï¼Ÿ

**4. New Bottleneckï¼ˆæ–°ç“¶é ¸ï¼‰**
- å•é¡Œå¾å“ªè£¡è½‰ç§»åˆ°å“ªè£¡ï¼Ÿ
- ä¸‹ä¸€å€‹éœ€è¦çªç ´çš„æ˜¯ä»€éº¼ï¼Ÿ

---

è«‹èšç„¦åœ¨å°å·¥ä½œæ–¹å¼æœ‰å¯¦è³ªå½±éŸ¿çš„æŠ€è¡“ï¼Œå¿½ç•¥ç´”å­¸è¡“æˆ–é æœŸçš„é€²å±•ã€‚
ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œé¡§å•èªè¨€ã€‚"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                    max_output_tokens=4000,
                ),
            )
            return response.text
        except Exception as e:
            return f"æŠ€è¡“åˆ†æç”ŸæˆéŒ¯èª¤: {e}"

    def _step5_company_analysis(self, raw_data: str, high_signal_events) -> str:
        """
        Step 5: Analyze company moves and strategic implications.
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸–ç•Œç´šä¼æ¥­ç­–ç•¥ç ”ç©¶åˆå¤¥äººã€‚

**ã€æœ¬æ­¥é©Ÿçš„å¿…è¦è¼¸å‡ºã€‘**

åœ¨åˆ†æå…¬å¸ç­–ç•¥æ™‚ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºè‡³å°‘ä¸€å€‹ï¼š
ã€Constraint that cannot be negotiatedã€‘

ä¾‹å¦‚ï¼š
- è³‡æœ¬çµæ§‹
- ç®—åŠ› / ä¾›æ‡‰éˆ
- ç›£ç®¡é¢¨éšª
- çµ„ç¹”æ²»ç†æˆæœ¬

---

åŸºæ–¼ä»¥ä¸‹è³‡æ–™ï¼Œåˆ†ææœ¬é€±é‡è¦å…¬å¸çš„å‹•æ…‹ï¼š

{raw_data[:8000]}

---

å°æ¯ä¸€å®¶å‡ºç¾çš„é‡è¦å…¬å¸ï¼Œè«‹ç”¨ä»¥ä¸‹èªæ³•åˆ†æï¼š

## å…¬å¸å‹•æ…‹åˆ†æ

### [å…¬å¸åç¨±]

**1. è¡¨å±¤å‹•ä½œ**
- ä»–å€‘åšäº†ä»€éº¼ï¼Ÿï¼ˆå…·é«”äº‹å¯¦ï¼‰

**2. éš±å«ç´„æŸ**
- é€™å€‹å‹•ä½œé€éœ²äº†ä»€éº¼é™åˆ¶æˆ–å£“åŠ›ï¼Ÿ
- ç‚ºä»€éº¼æ˜¯ç¾åœ¨ï¼Ÿç‚ºä»€éº¼æ˜¯é€™å€‹é¸æ“‡ï¼Ÿ

**3. æˆ°ç•¥æ„åœ–**
- **å®ˆä»€éº¼ï¼Ÿ** - ä¿è­·å“ªäº›æ ¸å¿ƒè³‡ç”¢æˆ–åœ°ä½
- **æ‰“ä»€éº¼ï¼Ÿ** - é€²æ”»å“ªäº›æ–°å¸‚å ´æˆ–å°æ‰‹
- **å»¶é²ä»€éº¼ï¼Ÿ** - åˆ»æ„æ¨é²æˆ–è¿´é¿ä»€éº¼

**4. å°ç”¢æ¥­çš„å¤–æº¢å½±éŸ¿**
- **ä¾›æ‡‰éˆ** - ä¸Šä¸‹æ¸¸æœƒå¦‚ä½•åæ‡‰ï¼Ÿ
- **ç«¶çˆ­è€…** - å°æ‰‹å¿…é ˆå¦‚ä½•å›æ‡‰ï¼Ÿ
- **å®¢æˆ¶** - å®¢æˆ¶çš„é¸æ“‡å¦‚ä½•æ”¹è®Šï¼Ÿ

**5. ä¸‹ä¸€å€‹å¯è§€æ¸¬ä¿¡è™Ÿ**
- ä»€éº¼äº‹ä»¶ç™¼ç”Ÿï¼Œä»£è¡¨ä½ çš„åˆ¤æ–·æ˜¯å°çš„ï¼Ÿ
- ä»€éº¼äº‹ä»¶ç™¼ç”Ÿï¼Œä»£è¡¨ä½ çš„åˆ¤æ–·æ˜¯éŒ¯çš„ï¼Ÿ
- æ™‚é–“æ¡†æ¶æ˜¯å¤šä¹…ï¼Ÿ

---

åªåˆ†ææœ‰é‡å¤§å‹•ä½œçš„å…¬å¸ï¼ˆ3-5 å®¶ï¼‰ï¼Œä¸è¦åˆ—å‡ºæ‰€æœ‰æåŠçš„å…¬å¸ã€‚
ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œé¡§å•èªè¨€ã€‚æ˜ç¢ºå€åˆ†ã€äº‹å¯¦ã€‘ã€æ¨è«–ã€‘ã€å‡èªªã€‘ã€‚"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                    max_output_tokens=4000,
                ),
            )
            return response.text
        except Exception as e:
            return f"å…¬å¸åˆ†æç”ŸæˆéŒ¯èª¤: {e}"

    def _step6_final_report(
        self,
        high_signal_events,
        paradigm_shifts: list,
        tech_analysis: str,
        company_analysis: str,
    ) -> str:
        """
        Step 6: Generate the final weekly industry cognition report.
        """
        # Compile previous analyses
        events_text = high_signal_events.get("raw_response", "") if isinstance(high_signal_events, dict) else str(high_signal_events)
        shifts_text = paradigm_shifts[0].get("raw_response", "") if paradigm_shifts else ""

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸–ç•Œç´šå…¨ç”¢æ¥­ã€å•†æ¥­èˆ‡ç§‘æŠ€ç ”ç©¶åˆå¤¥äººã€‚
ä½ çš„è®€è€…æ˜¯é ‚å°–çš„å…¨çƒç®¡ç†é¡§å•èˆ‡æŠ•è³‡é¡§å•ï¼š
- ä»–å€‘å­¸ç¿’é€Ÿåº¦æ¥µå¿«
- ä½†ä¸é è¨­ç†Ÿæ‚‰ä»»ä½•å–®ä¸€ç”¢æ¥­
- å°ã€Œè³‡è¨Šé‡è¿°ã€é›¶å®¹å¿ï¼Œåªé—œå¿ƒã€ŒèªçŸ¥æ˜¯å¦è¢«æ›´æ–°ã€

åŸºæ–¼ä»¥ä¸‹åˆ†æçµæœï¼Œç”Ÿæˆæœ€çµ‚çš„ã€æ¯é€±ç”¢æ¥­èªçŸ¥æ›´æ–°å ±å‘Šã€‘ï¼š

## é«˜ä¿¡è™Ÿäº‹ä»¶åˆ†æ
{events_text[:3000]}

## ç¯„å¼ç§»è½‰åˆ†æ
{shifts_text[:2000]}

## æŠ€è¡“å‰æ²¿åˆ†æ
{tech_analysis[:2000]}

## å…¬å¸å‹•æ…‹åˆ†æ
{company_analysis[:2000]}

---

è«‹ç”Ÿæˆå ±å‘Šï¼Œçµæ§‹å¿…é ˆåš´æ ¼åŒ…å«ä»¥ä¸‹ç« ç¯€ï¼š

# æ¯é€±ç”¢æ¥­èªçŸ¥æ›´æ–°å ±å‘Š

## 0. This Week's Thesis
ï¼ˆä¸€å¥è©±ç¸½çµæœ¬é€±æœ€é‡è¦çš„èªçŸ¥æ›´æ–°ï¼‰

## 1. Executive Brief
ï¼ˆ8 æ¢é«˜å¯†åº¦æ´å¯Ÿï¼Œæ¯æ¢ 1-2 å¥è©±ï¼‰
- æ ¼å¼ï¼š[ç”¢æ¥­æ¨™ç±¤] æ´å¯Ÿå…§å®¹

## 2. Paradigm Shift Radar
ï¼ˆæœ¬é€±è­˜åˆ¥åˆ°çš„ç¯„å¼ç§»è½‰ä¿¡è™Ÿï¼‰
- ä½¿ç”¨ã€Œå¾ A â†’ Bã€å¥å‹
- æ¨™æ³¨ä¿¡å¿ƒç¨‹åº¦å’Œæ™‚é–“å°ºåº¦

## 3. Industry Cognition Map Updates
ï¼ˆå“ªäº›è¡Œæ¥­èªçŸ¥éœ€è¦æ›´æ–°ï¼‰
- èˆŠèªçŸ¥ vs æ–°èªçŸ¥
- æ›´æ–°åŸå› 

## 4. Technology Frontier
ï¼ˆæŠ€è¡“é€²å±•ï¼Œèšç„¦å·¥ä½œæ”¹å¯«ï¼‰
- åªåˆ—å‡ºæœƒå¯¦è³ªæ”¹è®Šå·¥ä½œæ–¹å¼çš„æŠ€è¡“
- ä½¿ç”¨ Capability Delta + Workflow Rewrite æ¡†æ¶

## 5. Company Moves & Strategic Implications
ï¼ˆé‡è¦å…¬å¸å‹•æ…‹åŠå…¶ç­–ç•¥å«ç¾©ï¼‰
- è¡¨å±¤å‹•ä½œ â†’ éš±å«ç´„æŸ â†’ æˆ°ç•¥æ„åœ–
- å¤–æº¢å½±éŸ¿

## 6. IP / Regulation / Talent Signals
ï¼ˆå¦‚æœ‰ç›¸é—œè³‡è¨Šï¼‰
- å°ˆåˆ©å‹•æ…‹
- ç›£ç®¡è®ŠåŒ–
- äººæ‰æµå‹•

## 7. Key Metrics & Benchmarks
ï¼ˆæœ¬é€±é‡è¦æ•¸æ“šé»ï¼‰
- ç”¨è¡¨æ ¼å‘ˆç¾
- æ¨™æ³¨èˆ‡ä¸Šé€±/é æœŸçš„æ¯”è¼ƒ

## 8. Watchlist & Scenarios
ï¼ˆæœªä¾† 4-12 é€±é—œæ³¨äº‹é …ï¼‰
- å¾…é©—è­‰çš„å‡èªª
- é—œéµè§€å¯ŸæŒ‡æ¨™
- æƒ…å¢ƒæ¨æ¼”

---

å¯«ä½œè¦æ±‚ï¼š
- ä½¿ç”¨é¡§å•èªè¨€ï¼Œè€Œéåª’é«”èªè¨€
- æ˜ç¢ºå€åˆ†ã€äº‹å¯¦ã€‘ã€æ¨è«–ã€‘ã€ä¸ç¢ºå®šä½†å€¼å¾—è¿½è¹¤çš„å‡èªªã€‘
- ä¸ä½¿ç”¨æ–°èå¼å½¢å®¹è©ï¼ˆå¦‚ã€Œéœ‡é©šã€ã€Œé‡ç£…ã€ï¼‰
- å‡è¨­è®€è€…æ™‚é–“æ¥µå…¶æœ‰é™
- ä½¿ç”¨ç¹é«”ä¸­æ–‡"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.4,
                    max_output_tokens=8000,
                ),
            )
            return response.text
        except Exception as e:
            return f"å ±å‘Šç”ŸæˆéŒ¯èª¤: {e}"

    def quick_analysis(self, intel_items: list[IntelItem]) -> str:
        """
        Quick single-prompt analysis for testing or simpler use cases.
        """
        raw_data = self._format_raw_data(intel_items)

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸–ç•Œç´šå…¨ç”¢æ¥­ç ”ç©¶åˆå¤¥äººã€‚

ä»¥ä¸‹æ˜¯æœ¬é€±çš„æƒ…å ±è³‡æ–™ï¼š

{raw_data[:10000]}

---

è«‹ç”Ÿæˆä¸€ä»½ç²¾ç°¡çš„ã€æ¯é€±ç”¢æ¥­èªçŸ¥æ›´æ–°ã€‘ï¼ŒåŒ…å«ï¼š

1. **æœ¬é€±ä¸»é¡Œ**ï¼ˆä¸€å¥è©±ï¼‰

2. **äº”å¤§é«˜ä¿¡è™Ÿäº‹ä»¶**
   - äº‹ä»¶æ‘˜è¦
   - ç‚ºä½•é‡è¦ï¼ˆSo what?ï¼‰

3. **ç¯„å¼ç§»è½‰ä¿¡è™Ÿ**ï¼ˆå¦‚æœ‰ï¼‰
   - å¾ A â†’ B çš„è®ŠåŒ–
   - ä¿¡å¿ƒç¨‹åº¦

4. **å…¬å¸å‹•æ…‹é‡é»**ï¼ˆ2-3 å®¶ï¼‰
   - å‹•ä½œ + æˆ°ç•¥æ„åœ–

5. **ä¸‹é€±é—œæ³¨**
   - å¾…é©—è­‰å‡èªª
   - è§€å¯ŸæŒ‡æ¨™

ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œé¡§å•èªè¨€ï¼Œ800-1000 å­—ã€‚"""

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3,
                    max_output_tokens=3000,
                ),
            )
            return response.text
        except Exception as e:
            return f"åˆ†æç”ŸæˆéŒ¯èª¤: {e}"


def main():
    """Test the industry analyzer."""
    from src.collectors.intel_aggregator import IntelAggregator

    print("\n" + "="*60)
    print("Testing Industry Analyzer")
    print("="*60)

    # Collect data
    aggregator = IntelAggregator()
    items = aggregator.collect_all(days_lookback=7)

    if not items:
        print("No items collected. Exiting.")
        return

    # Quick analysis
    print("\n--- Quick Analysis ---\n")
    analyzer = IndustryAnalyzer()
    quick_result = analyzer.quick_analysis(items[:50])
    print(quick_result)

    # Full pipeline (uncomment to test)
    # print("\n--- Full Pipeline Analysis ---\n")
    # result = analyzer.analyze(items[:50], run_full_pipeline=True)
    # print(result.final_report)


if __name__ == "__main__":
    main()
